{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport spacy\nfrom string import digits\nimport random\nfrom torchtext.data.utils import get_tokenizer\nimport torch\nimport torchtext\nfrom collections import Counter\nfrom torchtext.vocab import vocab\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\n#torch.cuda.empty_cache()\n\nimport math\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-13T18:32:31.856329Z","iopub.execute_input":"2023-04-13T18:32:31.856986Z","iopub.status.idle":"2023-04-13T18:32:56.631781Z","shell.execute_reply.started":"2023-04-13T18:32:31.856925Z","shell.execute_reply":"2023-04-13T18:32:56.630674Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/en-fr-translation-dataset/en-fr.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"SEED = 97\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\n#torch.manual_seed(SEED)\n# torch.cuda.manual_seed(SEED)\n# torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:32:56.633828Z","iopub.execute_input":"2023-04-13T18:32:56.635059Z","iopub.status.idle":"2023-04-13T18:32:56.642897Z","shell.execute_reply.started":"2023-04-13T18:32:56.635009Z","shell.execute_reply":"2023-04-13T18:32:56.641834Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!python -m spacy download en_core_web_sm\n!python -m spacy download fr_core_news_sm","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:32:56.644772Z","iopub.execute_input":"2023-04-13T18:32:56.645259Z","iopub.status.idle":"2023-04-13T18:33:49.450979Z","shell.execute_reply.started":"2023-04-13T18:32:56.645216Z","shell.execute_reply":"2023-04-13T18:33:49.449671Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting en-core-web-sm==3.5.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /opt/conda/lib/python3.7/site-packages (from en-core-web-sm==3.5.0) (3.5.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.21.6)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\nRequirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\nRequirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.4)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\nRequirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\nRequirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (59.8.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.11.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.14)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.11.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\nCollecting fr-core-news-sm==3.5.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.5.0/fr_core_news_sm-3.5.0-py3-none-any.whl (16.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /opt/conda/lib/python3.7/site-packages (from fr-core-news-sm==3.5.0) (3.5.1)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.0.8)\nRequirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (4.4.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (6.3.0)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.0.12)\nRequirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.10.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (59.8.0)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.0.9)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (4.64.1)\nRequirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (8.1.9)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.4.6)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.1.1)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.3.0)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.21.6)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.10.4)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.28.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (23.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.1.2)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.0.4)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.0.8)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.0.7)\nRequirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.7.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.11.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.26.14)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.7.9)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.0.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.1.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (4.11.4)\nInstalling collected packages: fr-core-news-sm\nSuccessfully installed fr-core-news-sm-3.5.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('fr_core_news_sm')\n","output_type":"stream"}]},{"cell_type":"code","source":"MAX_LEN = 256\ncheck_len = lambda x: len(x.split(' ')) > MAX_LEN","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:49.455379Z","iopub.execute_input":"2023-04-13T18:33:49.455721Z","iopub.status.idle":"2023-04-13T18:33:49.464617Z","shell.execute_reply.started":"2023-04-13T18:33:49.455684Z","shell.execute_reply":"2023-04-13T18:33:49.463422Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/en-fr-translation-dataset/en-fr.csv', nrows=5000)\ndata = data.dropna().drop_duplicates()\ndata = data.drop(data[data.en.apply(check_len) | data.fr.apply(check_len)].index)\ndata.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:49.466544Z","iopub.execute_input":"2023-04-13T18:33:49.467581Z","iopub.status.idle":"2023-04-13T18:33:49.563920Z","shell.execute_reply.started":"2023-04-13T18:33:49.467506Z","shell.execute_reply":"2023-04-13T18:33:49.562857Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                  en  \\\n0  Changing Lives | Changing Society | How It Wor...   \n1                                           Site map   \n2                                           Feedback   \n3                                            Credits   \n4                                           Français   \n\n                                                  fr  \n0  Il a transformé notre vie | Il a transformé la...  \n1                                       Plan du site  \n2                                        Rétroaction  \n3                                            Crédits  \n4                                            English  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>fr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Changing Lives | Changing Society | How It Wor...</td>\n      <td>Il a transformé notre vie | Il a transformé la...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Site map</td>\n      <td>Plan du site</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Feedback</td>\n      <td>Rétroaction</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Credits</td>\n      <td>Crédits</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Français</td>\n      <td>English</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"len(data)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:49.565361Z","iopub.execute_input":"2023-04-13T18:33:49.566054Z","iopub.status.idle":"2023-04-13T18:33:49.573234Z","shell.execute_reply.started":"2023-04-13T18:33:49.566014Z","shell.execute_reply":"2023-04-13T18:33:49.571996Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"4998"},"metadata":{}}]},{"cell_type":"code","source":"fr_tokenizer = get_tokenizer('spacy', language='fr_core_news_sm')\nen_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:49.575301Z","iopub.execute_input":"2023-04-13T18:33:49.575680Z","iopub.status.idle":"2023-04-13T18:33:56.170729Z","shell.execute_reply.started":"2023-04-13T18:33:49.575642Z","shell.execute_reply":"2023-04-13T18:33:56.169587Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"val_frac = 0.1\ntest_frac = 0.05\nval_split_idx = int(len(data)*val_frac)\ntest_split_idx = int(len(data)*(val_frac + test_frac))\ndata_idx = list(range(len(data)))\nnp.random.shuffle(data_idx)\n\nval_idx, test_idx, train_idx = data_idx[:val_split_idx], data_idx[val_split_idx:test_split_idx], data_idx[test_split_idx:]\nprint('Length of train set: ', len(train_idx))\nprint('Length of val set: ', len(val_idx))\nprint('Length of test set: ', len(test_idx))\n\ndf_train = data.iloc[train_idx].reset_index().drop('index',axis=1)\ndf_test = data.iloc[test_idx].reset_index().drop('index',axis=1)\ndf_val = data.iloc[val_idx].reset_index().drop('index',axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:56.172138Z","iopub.execute_input":"2023-04-13T18:33:56.172516Z","iopub.status.idle":"2023-04-13T18:33:56.190703Z","shell.execute_reply.started":"2023-04-13T18:33:56.172475Z","shell.execute_reply":"2023-04-13T18:33:56.189527Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Length of train set:  4249\nLength of val set:  499\nLength of test set:  250\n","output_type":"stream"}]},{"cell_type":"code","source":"def build_vocab(data, source_tokenizer, target_tokenizer):\n    en_counter = Counter()\n    fr_counter = Counter()\n    translations = data.values.tolist()\n    for translation in translations:\n        en_counter.update(source_tokenizer(translation[0]))\n        fr_counter.update(target_tokenizer(translation[1]))\n    return vocab(en_counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'], min_freq=5), vocab(fr_counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'], min_freq=5)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:56.192425Z","iopub.execute_input":"2023-04-13T18:33:56.192807Z","iopub.status.idle":"2023-04-13T18:33:56.201267Z","shell.execute_reply.started":"2023-04-13T18:33:56.192768Z","shell.execute_reply":"2023-04-13T18:33:56.200140Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"en_vocab, fr_vocab = build_vocab(df_train, en_tokenizer, fr_tokenizer)\nen_vocab.set_default_index(en_vocab['<unk>'])\nfr_vocab.set_default_index(fr_vocab['<unk>'])","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:56.206526Z","iopub.execute_input":"2023-04-13T18:33:56.206981Z","iopub.status.idle":"2023-04-13T18:33:57.821016Z","shell.execute_reply.started":"2023-04-13T18:33:56.206926Z","shell.execute_reply":"2023-04-13T18:33:57.819809Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def data_process(data):\n    translations = data.values.tolist()\n    pairs = []\n    for translation in translations:\n        en_tensor = torch.tensor([en_vocab[token] for token in en_tokenizer(translation[0])],\n                            dtype=torch.long)\n        fr_tensor = torch.tensor([fr_vocab[token] for token in fr_tokenizer(translation[1])],\n                            dtype=torch.long)\n        pairs.append((en_tensor, fr_tensor))\n    return pairs","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:57.822344Z","iopub.execute_input":"2023-04-13T18:33:57.822728Z","iopub.status.idle":"2023-04-13T18:33:57.829271Z","shell.execute_reply.started":"2023-04-13T18:33:57.822689Z","shell.execute_reply":"2023-04-13T18:33:57.828180Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_data = data_process(df_train)\nval_data = data_process(df_val)\ntest_data = data_process(df_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:57.830870Z","iopub.execute_input":"2023-04-13T18:33:57.831826Z","iopub.status.idle":"2023-04-13T18:33:58.609898Z","shell.execute_reply.started":"2023-04-13T18:33:57.831785Z","shell.execute_reply":"2023-04-13T18:33:58.608792Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16\nPAD_IDX = en_vocab['<pad>']\nBOS_IDX = en_vocab['<bos>']\nEOS_IDX = en_vocab['<eos>']","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:58.611400Z","iopub.execute_input":"2023-04-13T18:33:58.612444Z","iopub.status.idle":"2023-04-13T18:33:58.618742Z","shell.execute_reply.started":"2023-04-13T18:33:58.612399Z","shell.execute_reply":"2023-04-13T18:33:58.617467Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def generate_batch(data_batch):\n    en_batch, fr_batch = [], []\n    for (en_item, fr_item) in data_batch:\n        en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0).to(device))\n        fr_batch.append(torch.cat([torch.tensor([BOS_IDX]), fr_item, torch.tensor([EOS_IDX])], dim=0).to(device))  \n        \n    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n    fr_batch = pad_sequence(fr_batch, padding_value=PAD_IDX)\n    return en_batch, fr_batch","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:58.620564Z","iopub.execute_input":"2023-04-13T18:33:58.621301Z","iopub.status.idle":"2023-04-13T18:33:58.629979Z","shell.execute_reply.started":"2023-04-13T18:33:58.621256Z","shell.execute_reply":"2023-04-13T18:33:58.628658Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_data, batch_size=BATCH_SIZE,\n                        shuffle=True, collate_fn=generate_batch)\nval_loader = DataLoader(val_data, batch_size=BATCH_SIZE,\n                        shuffle=True, collate_fn=generate_batch)\ntest_loader = DataLoader(test_data, batch_size=BATCH_SIZE,\n                        shuffle=True, collate_fn=generate_batch)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:58.631575Z","iopub.execute_input":"2023-04-13T18:33:58.632036Z","iopub.status.idle":"2023-04-13T18:33:58.641002Z","shell.execute_reply.started":"2023-04-13T18:33:58.631993Z","shell.execute_reply":"2023-04-13T18:33:58.639821Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, kernel_size, dropout, device):\n        super().__init__()\n        \n        assert kernel_size % 2 == 1, \"Kernel size must be odd!\"\n        \n        self.input_dim = input_dim\n        self.emb_dim = emb_dim\n        self.hid_dim = hid_dim\n        self.kernel_size = kernel_size\n        self.dropout = dropout\n        self.device = device\n        \n        self.scale = torch.sqrt(torch.FloatTensor([0.5])).to(device)\n        \n        self.tok_embedding = nn.Embedding(input_dim, emb_dim)\n        self.pos_embedding = nn.Embedding(100, emb_dim)\n        \n        self.emb2hid = nn.Linear(emb_dim, hid_dim)\n        self.hid2emb = nn.Linear(hid_dim, emb_dim)\n        \n        self.convs = nn.ModuleList([nn.Conv1d(in_channels = hid_dim, \n                                              out_channels = 2 * hid_dim, \n                                              kernel_size = kernel_size, \n                                              padding = (kernel_size - 1) // 2)\n                                    for _ in range(n_layers)])\n        \n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, src):\n        \n        #src = [batch size, src sent len]\n        \n        #create position tensor\n        pos = torch.arange(0, src.shape[1]).unsqueeze(0).repeat(src.shape[0], 1).to(self.device)\n        \n        #pos = [batch size, src sent len]\n        \n        #embed tokens and positions\n        tok_embedded = self.tok_embedding(src)\n        pos_embedded = self.pos_embedding(pos)\n        \n        #tok_embedded = pos_embedded = [batch size, src sent len, emb dim]\n        \n        #combine embeddings by elementwise summing\n        embedded = self.dropout(tok_embedded + pos_embedded)\n        \n        #embedded = [batch size, src sent len, emb dim]\n        \n        #pass embedded through linear layer to go through emb dim -> hid dim\n        conv_input = self.emb2hid(embedded)\n        \n        #conv_input = [batch size, src sent len, hid dim]\n        \n        #permute for convolutional layer\n        conv_input = conv_input.permute(0, 2, 1) \n        \n        #conv_input = [batch size, hid dim, src sent len]\n        \n        for i, conv in enumerate(self.convs):\n        \n            #pass through convolutional layer\n            conved = conv(self.dropout(conv_input))\n\n            #conved = [batch size, 2*hid dim, src sent len]\n\n            #pass through GLU activation function\n            conved = F.glu(conved, dim = 1)\n\n            #conved = [batch size, hid dim, src sent len]\n            \n            #apply residual connection\n            conved = (conved + conv_input) * self.scale\n\n            #conved = [batch size, hid dim, src sent len]\n            \n            #set conv_input to conved for next loop iteration\n            conv_input = conved\n        \n        #permute and convert back to emb dim\n        conved = self.hid2emb(conved.permute(0, 2, 1))\n        \n        #conved = [batch size, src sent len, emb dim]\n        \n        #elementwise sum output (conved) and input (embedded) to be used for attention\n        combined = (conved + embedded) * self.scale\n        \n        #combined = [batch size, src sent len, emb dim]\n        \n        return conved, combined","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:58.644522Z","iopub.execute_input":"2023-04-13T18:33:58.644885Z","iopub.status.idle":"2023-04-13T18:33:58.663130Z","shell.execute_reply.started":"2023-04-13T18:33:58.644842Z","shell.execute_reply":"2023-04-13T18:33:58.661992Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, kernel_size, dropout, pad_idx, device):\n        super().__init__()\n        \n        self.output_dim = output_dim\n        self.emb_dim = emb_dim\n        self.hid_dim = hid_dim\n        self.kernel_size = kernel_size\n        self.dropout = dropout\n        self.pad_idx = pad_idx\n        self.device = device\n        \n        self.scale = torch.sqrt(torch.FloatTensor([0.5])).to(device)\n        \n        self.tok_embedding = nn.Embedding(output_dim, emb_dim)\n        self.pos_embedding = nn.Embedding(100, emb_dim)\n        \n        self.emb2hid = nn.Linear(emb_dim, hid_dim)\n        self.hid2emb = nn.Linear(hid_dim, emb_dim)\n        \n        self.attn_hid2emb = nn.Linear(hid_dim, emb_dim)\n        self.attn_emb2hid = nn.Linear(emb_dim, hid_dim)\n        \n        self.out = nn.Linear(emb_dim, output_dim)\n        \n        self.convs = nn.ModuleList([nn.Conv1d(hid_dim, 2*hid_dim, kernel_size)\n                                    for _ in range(n_layers)])\n        \n        self.dropout = nn.Dropout(dropout)\n      \n    def calculate_attention(self, embedded, conved, encoder_conved, encoder_combined):\n        \n        #embedded = [batch size, trg sent len, emb dim]\n        #conved = [batch size, hid dim, trg sent len]\n        #encoder_conved = encoder_combined = [batch size, src sent len, emb dim]\n        \n        #permute and convert back to emb dim\n        conved_emb = self.attn_hid2emb(conved.permute(0, 2, 1))\n        \n        #conved_emb = [batch size, trg sent len, emb dim]\n        \n        combined = (embedded + conved_emb) * self.scale\n        \n        #combined = [batch size, trg sent len, emb dim]\n                \n        energy = torch.matmul(combined, encoder_conved.permute(0, 2, 1))\n        \n        #energy = [batch size, trg sent len, src sent len]\n        \n        attention = F.softmax(energy, dim=2)\n        \n        #attention = [batch size, trg sent len, src sent len]\n            \n        attended_encoding = torch.matmul(attention, (encoder_conved + encoder_combined))\n        \n        #attended_encoding = [batch size, trg sent len, emd dim]\n        \n        #convert from emb dim -> hid dim\n        attended_encoding = self.attn_emb2hid(attended_encoding)\n        \n        #attended_encoding = [batch size, trg sent len, hid dim]\n        \n        attended_combined = (conved + attended_encoding.permute(0, 2, 1)) * self.scale\n        \n        #attended_combined = [batch size, hid dim, trg sent len]\n        \n        return attention, attended_combined\n        \n    def forward(self, trg, encoder_conved, encoder_combined):\n        \n        #trg = [batch size, trg sent len]\n        #encoder_conved = encoder_combined = [batch size, src sent len, emb dim]\n                \n        #create position tensor\n        pos = torch.arange(0, trg.shape[1]).unsqueeze(0).repeat(trg.shape[0], 1).to(device)\n        \n        #pos = [batch size, trg sent len]\n        \n        #embed tokens and positions\n        tok_embedded = self.tok_embedding(trg)\n        pos_embedded = self.pos_embedding(pos)\n        \n        #tok_embedded = [batch size, trg sent len, emb dim]\n        #pos_embedded = [batch size, trg sent len, emb dim]\n        \n        #combine embeddings by elementwise summing\n        embedded = self.dropout(tok_embedded + pos_embedded)\n        \n        #embedded = [batch size, trg sent len, emb dim]\n        \n        #pass embedded through linear layer to go through emb dim -> hid dim\n        conv_input = self.emb2hid(embedded)\n        \n        #conv_input = [batch size, trg sent len, hid dim]\n        \n        #permute for convolutional layer\n        conv_input = conv_input.permute(0, 2, 1) \n        \n        #conv_input = [batch size, hid dim, trg sent len]\n        \n        for i, conv in enumerate(self.convs):\n        \n            #apply dropout\n            conv_input = self.dropout(conv_input)\n        \n            #need to pad so decoder can't \"cheat\"\n            padding = torch.zeros(conv_input.shape[0], conv_input.shape[1], self.kernel_size-1).fill_(self.pad_idx).to(device)\n            padded_conv_input = torch.cat((padding, conv_input), dim=2)\n        \n            #padded_conv_input = [batch size, hid dim, trg sent len + kernel size - 1]\n        \n            #pass through convolutional layer\n            conved = conv(padded_conv_input)\n\n            #conved = [batch size, 2*hid dim, trg sent len]\n            \n            #pass through GLU activation function\n            conved = F.glu(conved, dim=1)\n\n            #conved = [batch size, hid dim, trg sent len]\n            \n            attention, conved = self.calculate_attention(embedded, conved, encoder_conved, encoder_combined)\n            \n            #attention = [batch size, trg sent len, src sent len]\n            #conved = [batch size, hid dim, trg sent len]\n            \n            #apply residual connection\n            conved = (conved + conv_input) * self.scale\n            \n            #conved = [batch size, hid dim, trg sent len]\n            \n            #set conv_input to conved for next loop iteration\n            conv_input = conved\n            \n        conved = self.hid2emb(conved.permute(0, 2, 1))\n         \n        #conved = [batch size, trg sent len, hid dim]\n            \n        output = self.out(self.dropout(conved))\n        \n        #output = [batch size, trg sent len, output dim]\n            \n        return output, attention","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:58.666638Z","iopub.execute_input":"2023-04-13T18:33:58.668175Z","iopub.status.idle":"2023-04-13T18:33:58.686261Z","shell.execute_reply.started":"2023-04-13T18:33:58.668134Z","shell.execute_reply":"2023-04-13T18:33:58.685208Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, device):\n        super().__init__()\n        \n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n        \n    def forward(self, src, trg):\n        \n        #src = [batch size, src sent len]\n        #trg = [batch size, trg sent len]\n           \n        #calculate z^u (encoder_conved) and e (encoder_combined)\n        #encoder_conved is output from final encoder conv. block\n        #encoder_combined is encoder_conved plus (elementwise) src embedding plus positional embeddings \n        encoder_conved, encoder_combined = self.encoder(src)\n            \n        #encoder_conved = [batch size, src sent len, emb dim]\n        #encoder_combined = [batch size, src sent len, emb dim]\n        \n        #calculate predictions of next words\n        #output is a batch of predictions for each word in the trg sentence\n        #attention a batch of attention scores across the src sentence for each word in the trg sentence\n        output, attention = self.decoder(trg, encoder_conved, encoder_combined)\n        \n        #output = [batch size, trg sent len, output dim]\n        #attention = [batch size, trg sent len, src sent len]\n        \n        return output, attention","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:58.689729Z","iopub.execute_input":"2023-04-13T18:33:58.690765Z","iopub.status.idle":"2023-04-13T18:33:58.699234Z","shell.execute_reply.started":"2023-04-13T18:33:58.690721Z","shell.execute_reply":"2023-04-13T18:33:58.698185Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"INPUT_DIM = len(en_vocab)\nOUTPUT_DIM = len(fr_vocab)\nEMB_DIM = 256\nHID_DIM = 512\nENC_LAYERS = 10\nDEC_LAYERS = 10\nENC_KERNEL_SIZE = 3\nDEC_KERNEL_SIZE = 3\nENC_DROPOUT = 0.25\nDEC_DROPOUT = 0.25\nPAD_IDX = fr_vocab['<pad>']\n    \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \nenc = Encoder(INPUT_DIM, EMB_DIM, HID_DIM, ENC_LAYERS, ENC_KERNEL_SIZE, ENC_DROPOUT, device)\ndec = Decoder(OUTPUT_DIM, EMB_DIM, HID_DIM, DEC_LAYERS, DEC_KERNEL_SIZE, DEC_DROPOUT, PAD_IDX, device)\n\nmodel = Seq2Seq(enc, dec, device).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:58.700775Z","iopub.execute_input":"2023-04-13T18:33:58.702088Z","iopub.status.idle":"2023-04-13T18:33:59.141966Z","shell.execute_reply.started":"2023-04-13T18:33:58.701993Z","shell.execute_reply":"2023-04-13T18:33:59.140907Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f'The model has {count_parameters(model):,} trainable parameters')","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:59.143255Z","iopub.execute_input":"2023-04-13T18:33:59.143621Z","iopub.status.idle":"2023-04-13T18:33:59.151291Z","shell.execute_reply.started":"2023-04-13T18:33:59.143582Z","shell.execute_reply":"2023-04-13T18:33:59.150002Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"The model has 33,838,523 trainable parameters\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters())\ncriterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:59.153080Z","iopub.execute_input":"2023-04-13T18:33:59.153783Z","iopub.status.idle":"2023-04-13T18:33:59.161353Z","shell.execute_reply.started":"2023-04-13T18:33:59.153740Z","shell.execute_reply":"2023-04-13T18:33:59.159992Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def train(model, dataloader, optimizer, criterion, clip):\n    \n    model.train()\n    \n    epoch_loss = 0\n    \n    for i, (src, trg) in enumerate(dataloader):   \n        print(src.size())\n        src = src.permute(1, 0)\n        trg = trg.permute(1, 0)\n        \n        optimizer.zero_grad()\n        \n        output, _ = model(src, trg[:,:-1])\n        \n        #output = [batch size, trg sent len - 1, output dim]\n        #trg = [batch size, trg sent len]\n        \n        output = output.contiguous().view(-1, output.shape[-1])\n        trg = trg[:,1:].contiguous().view(-1)\n        \n        #output = [batch size * trg sent len - 1, output dim]\n        #trg = [batch size * trg sent len - 1]\n        \n        loss = criterion(output, trg)\n        \n        loss.backward()\n        \n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        \n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        \n    return epoch_loss / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:59.163272Z","iopub.execute_input":"2023-04-13T18:33:59.164191Z","iopub.status.idle":"2023-04-13T18:33:59.174502Z","shell.execute_reply.started":"2023-04-13T18:33:59.164141Z","shell.execute_reply":"2023-04-13T18:33:59.173397Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, dataloader, criterion):\n    \n    model.eval()\n    \n    epoch_loss = 0\n    \n    with torch.no_grad():\n        for i, (src, trg) in enumerate(dataloader):\n            src = src.permute(1, 0)\n            trg = trg.permute(1, 0)\n            output, _ = model(src, trg[:,:-1])\n        \n            #output = [batch size, trg sent len - 1, output dim]\n            #trg = [batch size, trg sent len]\n\n            output = output.contiguous().view(-1, output.shape[-1])\n            trg = trg[:,1:].contiguous().view(-1)\n\n            #output = [batch size * trg sent len - 1, output dim]\n            #trg = [batch size * trg sent len - 1]\n            \n            loss = criterion(output, trg)\n\n            epoch_loss += loss.item()\n        \n    return epoch_loss / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:59.176259Z","iopub.execute_input":"2023-04-13T18:33:59.176665Z","iopub.status.idle":"2023-04-13T18:33:59.187112Z","shell.execute_reply.started":"2023-04-13T18:33:59.176627Z","shell.execute_reply":"2023-04-13T18:33:59.185924Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:59.188743Z","iopub.execute_input":"2023-04-13T18:33:59.189771Z","iopub.status.idle":"2023-04-13T18:33:59.197254Z","shell.execute_reply.started":"2023-04-13T18:33:59.189714Z","shell.execute_reply":"2023-04-13T18:33:59.196511Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"MODEL_PATH = 'cnn-encoder-decoder-attn-model.pt'","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:59.198622Z","iopub.execute_input":"2023-04-13T18:33:59.199820Z","iopub.status.idle":"2023-04-13T18:33:59.208915Z","shell.execute_reply.started":"2023-04-13T18:33:59.199768Z","shell.execute_reply":"2023-04-13T18:33:59.208229Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"N_EPOCHS = 5\nCLIP = 1\n\nbest_valid_loss = float('inf')\n\nfor epoch in range(N_EPOCHS):\n    \n    start_time = time.time()\n    \n    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n    valid_loss = evaluate(model, valid_loader, criterion)\n    \n    end_time = time.time()\n    \n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n    \n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), MODEL_PATH)\n    \n    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:33:59.210383Z","iopub.execute_input":"2023-04-13T18:33:59.211480Z","iopub.status.idle":"2023-04-13T18:34:05.992556Z","shell.execute_reply.started":"2023-04-13T18:33:59.211441Z","shell.execute_reply":"2023-04-13T18:34:05.985804Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"torch.Size([32, 16])\ntorch.Size([32, 16])\ntorch.Size([36, 16])\ntorch.Size([78, 16])\ntorch.Size([32, 16])\ntorch.Size([39, 16])\ntorch.Size([41, 16])\ntorch.Size([28, 16])\ntorch.Size([40, 16])\ntorch.Size([44, 16])\ntorch.Size([83, 16])\ntorch.Size([30, 16])\ntorch.Size([28, 16])\ntorch.Size([30, 16])\ntorch.Size([62, 16])\ntorch.Size([40, 16])\ntorch.Size([76, 16])\ntorch.Size([59, 16])\ntorch.Size([41, 16])\ntorch.Size([39, 16])\ntorch.Size([34, 16])\ntorch.Size([57, 16])\ntorch.Size([44, 16])\ntorch.Size([78, 16])\ntorch.Size([48, 16])\ntorch.Size([33, 16])\ntorch.Size([43, 16])\ntorch.Size([103, 16])\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [200,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1141: indexSelectLargeIndex: block: [165,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/2026667036.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/1709531695.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#output = [batch size, trg sent len - 1, output dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/3920021203.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#output is a batch of predictions for each word in the trg sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#attention a batch of attention scores across the src sentence for each word in the trg sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_conved\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_combined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#output = [batch size, trg sent len, output dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/1579354732.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, trg, encoder_conved, encoder_combined)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m#create position tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m#pos = [batch size, trg sent len]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."],"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.","output_type":"error"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load(MODEL_PATH))\ntest_loss = evaluate(model, test_loader, criterion)\nprint(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')","metadata":{"execution":{"iopub.status.busy":"2023-04-13T18:34:05.997509Z","iopub.status.idle":"2023-04-13T18:34:06.002691Z","shell.execute_reply.started":"2023-04-13T18:34:06.001352Z","shell.execute_reply":"2023-04-13T18:34:06.001619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}