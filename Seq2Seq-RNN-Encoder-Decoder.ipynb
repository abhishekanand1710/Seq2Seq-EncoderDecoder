{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e0ae70f",
   "metadata": {
    "papermill": {
     "duration": 0.01034,
     "end_time": "2023-04-13T11:09:29.079579",
     "exception": false,
     "start_time": "2023-04-13T11:09:29.069239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This is an implementation for Sequence to Sequence Encoder - Decoder Model using LSTM trained for the task of English-French translations. It is based on the paper - [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215) and the notebook [Pytorch Seq2Seq](https://github.com/SethHWeidman/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb). \n",
    "\n",
    "It is implemented as an excerise to gain a deeper understanding of Encoder - Decoder models and build on it to explore advancements on the same.\n",
    "\n",
    "Dataset used - [English - French Translations](https://www.kaggle.com/datasets/dhruvildave/en-fr-translation-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e74d6de",
   "metadata": {
    "papermill": {
     "duration": 0.008134,
     "end_time": "2023-04-13T11:09:29.096114",
     "exception": false,
     "start_time": "2023-04-13T11:09:29.087980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model training walkthrough\n",
    "\n",
    "The idea behind such a model is to use the Encoder to encode the source sentence to a context vector, which the Decoder uses to generate the target sentence. \n",
    "\n",
    "Encoder Process - \n",
    "* Source sentence is split up into tokens and vocabularized. The sentences' tokens are passed into the model one by one using their indices from the vocab as input.\n",
    "* The input is fed to an embedding layer which learns to generate an embedding vector (E) for the word. (A pre-trained embedding can be utilised here to improve accuracy and reduce training time by freezing the layer)\n",
    "* E is fed into an RNN unit (either Vanilla RNN, LSTM or GRU) which also takes the hidden state of the previous token run as input (for the first token, it can be initialized as a randome vector or a tensor of 0s).\n",
    "* E vector and the hidden state of the previous token pass (Hi-1) is used as input by the RNN unit to generate output and hidden state.\n",
    "* The generated hidden state serves as the input to next token run, along with the next token's E vector.\n",
    "* The context vector from the encoder is the output(hidden state) of the final token run from the source sentence.\n",
    "* The context vector is used as the input to the decoder.\n",
    "\n",
    "example pseudocode for one sentence pass through encoder - \n",
    "\n",
    "<code>\n",
    "    vocab = build_vocab(source_sentence)\n",
    "    sentence_tensor = [vocab[tokenize(word)] for word in source_sentence.split(' ')]\n",
    "    hidden = 0\n",
    "    for word_tensor in sentence_tensor:\n",
    "        emb_vector = embed(word_tensor)\n",
    "        hidden, output = rnn_unit(emb_vector, hidden) # hidden = output for 1 layer rnn\n",
    "    context = hidden\n",
    "</code>\n",
    "\n",
    "<br/>\n",
    "Decoder process - \n",
    "* Target sentence is split up into tokens and vocabularized. The sentences' tokens are passed into the model one by one using their indices from the vocab as input.\n",
    "* The input is fed to an embedding layer which learns to generate an embedding vector (E) for the word. (A pre-trained embedding can be utilised here to improve accuracy and reduce training time by freezing the layer)\n",
    "* E is fed into an RNN unit (either Vanilla RNN, LSTM or GRU) which also takes the hidden state of the previous token run as input (for the first token, it is the context vector returned from the encoder).\n",
    "* The RNN unit uses E and hidden state from previous token as input and generates output vector and hidden state for the next token pass.\n",
    "* The output vector is passed through a linear layer with output dimension as the vocab size. Argmax of linear layer output is taken to get the index of token generated in vocab.\n",
    "* This token is then later used as input for the next token pass. \n",
    "* In case of teacher forcing approach, actual target token is used instead of generated token for next pass.\n",
    "\n",
    "example pseudocode for one sentence pass through decoder - \n",
    "\n",
    "<code>\n",
    "    vocab = build_vocab(target_sentence)\n",
    "    sentence_tensor = [vocab[tokenize(word)] for word in target_sentence.split(' ')]\n",
    "    hidden = context\n",
    "    word_tensor = sentence_tensor[0]\n",
    "    predicted_sentence = []\n",
    "    for i in range(len(sentence_tensor)):\n",
    "        emb_vector = embed(word_tensor)\n",
    "        hidden, output = rnn_unit(emb_vector, hidden) # hidden = output for 1 layer rnn\n",
    "        prediction = argmax(linear_layer(output))\n",
    "        word_tensor = prediction\n",
    "        predicted_sentence.append(prediction)\n",
    "</code>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629e39d4",
   "metadata": {
    "papermill": {
     "duration": 0.007952,
     "end_time": "2023-04-13T11:09:29.112326",
     "exception": false,
     "start_time": "2023-04-13T11:09:29.104374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Module imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8061b620",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-13T11:09:29.131621Z",
     "iopub.status.busy": "2023-04-13T11:09:29.131220Z",
     "iopub.status.idle": "2023-04-13T11:09:54.255867Z",
     "shell.execute_reply": "2023-04-13T11:09:54.254449Z"
    },
    "papermill": {
     "duration": 25.137366,
     "end_time": "2023-04-13T11:09:54.258254",
     "exception": false,
     "start_time": "2023-04-13T11:09:29.120888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/en-fr-translation-dataset/en-fr.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import random\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import torch\n",
    "import torchtext\n",
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b336aa0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:09:54.277896Z",
     "iopub.status.busy": "2023-04-13T11:09:54.276548Z",
     "iopub.status.idle": "2023-04-13T11:09:54.285209Z",
     "shell.execute_reply": "2023-04-13T11:09:54.284255Z"
    },
    "papermill": {
     "duration": 0.020301,
     "end_time": "2023-04-13T11:09:54.287329",
     "exception": false,
     "start_time": "2023-04-13T11:09:54.267028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 97\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae41abdc",
   "metadata": {
    "papermill": {
     "duration": 0.00811,
     "end_time": "2023-04-13T11:09:54.303792",
     "exception": false,
     "start_time": "2023-04-13T11:09:54.295682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Downloading Spacy models for use as tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea5b369",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-04-13T11:09:54.321456Z",
     "iopub.status.busy": "2023-04-13T11:09:54.321183Z",
     "iopub.status.idle": "2023-04-13T11:10:43.185962Z",
     "shell.execute_reply": "2023-04-13T11:10:43.184756Z"
    },
    "papermill": {
     "duration": 48.876889,
     "end_time": "2023-04-13T11:10:43.188836",
     "exception": false,
     "start_time": "2023-04-13T11:09:54.311947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /opt/conda/lib/python3.7/site-packages (from en-core-web-sm==3.5.0) (3.5.1)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\r\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\r\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\r\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.4)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (59.8.0)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.21.6)\r\n",
      "Requirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.11.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.14)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.11.4)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_sm')\r\n",
      "Collecting fr-core-news-sm==3.5.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.5.0/fr_core_news_sm-3.5.0-py3-none-any.whl (16.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /opt/conda/lib/python3.7/site-packages (from fr-core-news-sm==3.5.0) (3.5.1)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.1.1)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.3.0)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.28.2)\r\n",
      "Requirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (4.4.0)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.0.9)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.4.6)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (6.3.0)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.0.8)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.1.2)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.10.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (23.0)\r\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.10.1)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (4.64.1)\r\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.7.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (59.8.0)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.0.12)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.0.8)\r\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (8.1.9)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.0.7)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.0.4)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.21.6)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.11.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.26.14)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.1.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2022.12.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.4)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.7.9)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.0.4)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (8.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.1.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (4.11.4)\r\n",
      "Installing collected packages: fr-core-news-sm\r\n",
      "Successfully installed fr-core-news-sm-3.5.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\r\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509931d6",
   "metadata": {
    "papermill": {
     "duration": 0.009917,
     "end_time": "2023-04-13T11:10:43.209279",
     "exception": false,
     "start_time": "2023-04-13T11:10:43.199362",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data import\n",
    "Reading only 50000 rows for demonstration purposes. Training RNN is slow as it it takes input tokens one by one and I am limited by the compute available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb0ec250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:43.231548Z",
     "iopub.status.busy": "2023-04-13T11:10:43.230615Z",
     "iopub.status.idle": "2023-04-13T11:10:43.837899Z",
     "shell.execute_reply": "2023-04-13T11:10:43.836756Z"
    },
    "papermill": {
     "duration": 0.620957,
     "end_time": "2023-04-13T11:10:43.840229",
     "exception": false,
     "start_time": "2023-04-13T11:10:43.219272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Changing Lives | Changing Society | How It Wor...</td>\n",
       "      <td>Il a transformé notre vie | Il a transformé la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Site map</td>\n",
       "      <td>Plan du site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feedback</td>\n",
       "      <td>Rétroaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Credits</td>\n",
       "      <td>Crédits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Français</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0  Changing Lives | Changing Society | How It Wor...   \n",
       "1                                           Site map   \n",
       "2                                           Feedback   \n",
       "3                                            Credits   \n",
       "4                                           Français   \n",
       "\n",
       "                                                  fr  \n",
       "0  Il a transformé notre vie | Il a transformé la...  \n",
       "1                                       Plan du site  \n",
       "2                                        Rétroaction  \n",
       "3                                            Crédits  \n",
       "4                                            English  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/en-fr-translation-dataset/en-fr.csv', nrows=50000)\n",
    "data = data.dropna().drop_duplicates()\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f057741",
   "metadata": {
    "papermill": {
     "duration": 0.010277,
     "end_time": "2023-04-13T11:10:43.861617",
     "exception": false,
     "start_time": "2023-04-13T11:10:43.851340",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Initializing the tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1177eb04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:43.883781Z",
     "iopub.status.busy": "2023-04-13T11:10:43.883448Z",
     "iopub.status.idle": "2023-04-13T11:10:50.844792Z",
     "shell.execute_reply": "2023-04-13T11:10:50.843723Z"
    },
    "papermill": {
     "duration": 6.97517,
     "end_time": "2023-04-13T11:10:50.847508",
     "exception": false,
     "start_time": "2023-04-13T11:10:43.872338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fr_tokenizer = get_tokenizer('spacy', language='fr_core_news_sm')\n",
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07912d2",
   "metadata": {
    "papermill": {
     "duration": 0.010114,
     "end_time": "2023-04-13T11:10:50.868263",
     "exception": false,
     "start_time": "2023-04-13T11:10:50.858149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Splitting train, test and val datasets\n",
    "Train - 85%, Val - 10%, Test - 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db1921b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:50.889979Z",
     "iopub.status.busy": "2023-04-13T11:10:50.889640Z",
     "iopub.status.idle": "2023-04-13T11:10:50.920877Z",
     "shell.execute_reply": "2023-04-13T11:10:50.919711Z"
    },
    "papermill": {
     "duration": 0.045988,
     "end_time": "2023-04-13T11:10:50.924483",
     "exception": false,
     "start_time": "2023-04-13T11:10:50.878495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set -  42500\n",
      "Length of validation set -  4999\n",
      "Length of test set -  2500\n"
     ]
    }
   ],
   "source": [
    "val_frac = 0.1\n",
    "test_frac = 0.05\n",
    "\n",
    "val_split_idx = int(len(data)*val_frac)\n",
    "test_split_idx = int(len(data)*(val_frac + test_frac))\n",
    "\n",
    "data_idx = list(range(len(data)))\n",
    "np.random.shuffle(data_idx)\n",
    "\n",
    "val_idx, test_idx, train_idx = data_idx[:val_split_idx], data_idx[val_split_idx:test_split_idx], data_idx[test_split_idx:]\n",
    "\n",
    "df_train = data.iloc[train_idx].reset_index().drop('index',axis=1)\n",
    "df_val = data.iloc[val_idx].reset_index().drop('index',axis=1)\n",
    "df_test = data.iloc[test_idx].reset_index().drop('index',axis=1)\n",
    "\n",
    "print('Length of train set - ', len(df_train))\n",
    "print('Length of validation set - ', len(df_val))\n",
    "print('Length of test set - ', len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "007b72a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:50.947045Z",
     "iopub.status.busy": "2023-04-13T11:10:50.946049Z",
     "iopub.status.idle": "2023-04-13T11:10:50.952740Z",
     "shell.execute_reply": "2023-04-13T11:10:50.951817Z"
    },
    "papermill": {
     "duration": 0.020025,
     "end_time": "2023-04-13T11:10:50.954846",
     "exception": false,
     "start_time": "2023-04-13T11:10:50.934821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_vocab(data, source_tokenizer, target_tokenizer):\n",
    "    en_counter = Counter()\n",
    "    fr_counter = Counter()\n",
    "    translations = data.values.tolist()\n",
    "    for translation in translations:\n",
    "        en_counter.update(source_tokenizer(translation[0]))\n",
    "        fr_counter.update(target_tokenizer(translation[1]))\n",
    "    return vocab(en_counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'], min_freq=2), vocab(fr_counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'], min_freq=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc51004",
   "metadata": {
    "papermill": {
     "duration": 0.010025,
     "end_time": "2023-04-13T11:10:50.975171",
     "exception": false,
     "start_time": "2023-04-13T11:10:50.965146",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Building separate vocabs for English & French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edba7030",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:50.997575Z",
     "iopub.status.busy": "2023-04-13T11:10:50.996738Z",
     "iopub.status.idle": "2023-04-13T11:11:02.988917Z",
     "shell.execute_reply": "2023-04-13T11:11:02.987843Z"
    },
    "papermill": {
     "duration": 12.00589,
     "end_time": "2023-04-13T11:11:02.991422",
     "exception": false,
     "start_time": "2023-04-13T11:10:50.985532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_vocab, fr_vocab = build_vocab(df_train, en_tokenizer, fr_tokenizer)\n",
    "en_vocab.set_default_index(en_vocab['<unk>'])\n",
    "fr_vocab.set_default_index(fr_vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f491ead2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:03.014329Z",
     "iopub.status.busy": "2023-04-13T11:11:03.013805Z",
     "iopub.status.idle": "2023-04-13T11:11:03.020393Z",
     "shell.execute_reply": "2023-04-13T11:11:03.019308Z"
    },
    "papermill": {
     "duration": 0.020533,
     "end_time": "2023-04-13T11:11:03.022913",
     "exception": false,
     "start_time": "2023-04-13T11:11:03.002380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_process(data):\n",
    "    translations = data.values.tolist()\n",
    "    pairs = []\n",
    "    for translation in translations:\n",
    "        en_tensor = torch.tensor([en_vocab[token] for token in en_tokenizer(translation[0])][::-1],\n",
    "                            dtype=torch.long)\n",
    "        fr_tensor = torch.tensor([fr_vocab[token] for token in fr_tokenizer(translation[1])],\n",
    "                            dtype=torch.long)\n",
    "        pairs.append((en_tensor, fr_tensor))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bcb4689",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:03.044834Z",
     "iopub.status.busy": "2023-04-13T11:11:03.044534Z",
     "iopub.status.idle": "2023-04-13T11:11:11.542168Z",
     "shell.execute_reply": "2023-04-13T11:11:11.541131Z"
    },
    "papermill": {
     "duration": 8.511514,
     "end_time": "2023-04-13T11:11:11.544581",
     "exception": false,
     "start_time": "2023-04-13T11:11:03.033067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = data_process(df_train)\n",
    "val_data = data_process(df_val)\n",
    "test_data = data_process(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9b9a25",
   "metadata": {
    "papermill": {
     "duration": 0.010173,
     "end_time": "2023-04-13T11:11:11.565594",
     "exception": false,
     "start_time": "2023-04-13T11:11:11.555421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Note:\n",
    "Keeping a small batch size due to limitation of GPU size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "483f6214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:11.587759Z",
     "iopub.status.busy": "2023-04-13T11:11:11.587082Z",
     "iopub.status.idle": "2023-04-13T11:11:11.592670Z",
     "shell.execute_reply": "2023-04-13T11:11:11.591752Z"
    },
    "papermill": {
     "duration": 0.019001,
     "end_time": "2023-04-13T11:11:11.594787",
     "exception": false,
     "start_time": "2023-04-13T11:11:11.575786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "PAD_IDX = en_vocab['<pad>']\n",
    "BOS_IDX = en_vocab['<bos>']\n",
    "EOS_IDX = en_vocab['<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40d3fdc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:11.616601Z",
     "iopub.status.busy": "2023-04-13T11:11:11.616121Z",
     "iopub.status.idle": "2023-04-13T11:11:11.622866Z",
     "shell.execute_reply": "2023-04-13T11:11:11.621765Z"
    },
    "papermill": {
     "duration": 0.020018,
     "end_time": "2023-04-13T11:11:11.624966",
     "exception": false,
     "start_time": "2023-04-13T11:11:11.604948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_batch(data_batch):\n",
    "    en_batch, fr_batch = [], []\n",
    "    for (en_item, fr_item) in data_batch:\n",
    "        en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0).to(device))\n",
    "        fr_batch.append(torch.cat([torch.tensor([BOS_IDX]), fr_item, torch.tensor([EOS_IDX])], dim=0).to(device))  \n",
    "        \n",
    "    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
    "    fr_batch = pad_sequence(fr_batch, padding_value=PAD_IDX)\n",
    "    return en_batch, fr_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2204bc74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:11.647386Z",
     "iopub.status.busy": "2023-04-13T11:11:11.646435Z",
     "iopub.status.idle": "2023-04-13T11:11:11.652630Z",
     "shell.execute_reply": "2023-04-13T11:11:11.651732Z"
    },
    "papermill": {
     "duration": 0.019552,
     "end_time": "2023-04-13T11:11:11.654736",
     "exception": false,
     "start_time": "2023-04-13T11:11:11.635184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154b101b",
   "metadata": {
    "papermill": {
     "duration": 0.010056,
     "end_time": "2023-04-13T11:11:11.675052",
     "exception": false,
     "start_time": "2023-04-13T11:11:11.664996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Encoder\n",
    "* input_dim - source sentence vocab size\n",
    "* emb_dim - output size of embedding layer\n",
    "* hid_dim - Output size of hidden vector and output vector generated by RNN unit (LSTM in this case)\n",
    "* n_layers - No. of RNN layers(RNN units) to stack or which the token passes through ( In case of multiple layers, the final context vector has final hidden vectors generated from each layer stacked on top of each other)\n",
    "* dropout - percentage of droput to be used to avoid overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "543579e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:11.697560Z",
     "iopub.status.busy": "2023-04-13T11:11:11.696634Z",
     "iopub.status.idle": "2023-04-13T11:11:11.704122Z",
     "shell.execute_reply": "2023-04-13T11:11:11.703161Z"
    },
    "papermill": {
     "duration": 0.020991,
     "end_time": "2023-04-13T11:11:11.706213",
     "exception": false,
     "start_time": "2023-04-13T11:11:11.685222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        \n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        \n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb97bf5",
   "metadata": {
    "papermill": {
     "duration": 0.010049,
     "end_time": "2023-04-13T11:11:11.726519",
     "exception": false,
     "start_time": "2023-04-13T11:11:11.716470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Decoder\n",
    "* output_dim - target sentence vocab size\n",
    "* emb_dim - output size of embedding layer\n",
    "* hid_dim - Output size of hidden vector and output vector generated by RNN unit (LSTM in this case)\n",
    "* n_layers - No. of RNN layers(RNN units) to stack or which the token passes through (in this example we keep the number of layers same in case of encoder and decoder, so the generated context vector can be directly used in decoder without the need of any summartion or passing through a linear layer for transformation)\n",
    "* dropout - percentage of droput to be used to avoid overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15429765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:11.748129Z",
     "iopub.status.busy": "2023-04-13T11:11:11.747854Z",
     "iopub.status.idle": "2023-04-13T11:11:11.755882Z",
     "shell.execute_reply": "2023-04-13T11:11:11.754908Z"
    },
    "papermill": {
     "duration": 0.021254,
     "end_time": "2023-04-13T11:11:11.757937",
     "exception": false,
     "start_time": "2023-04-13T11:11:11.736683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        \n",
    "        #input = [batch size]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "                \n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        \n",
    "        #output = [seq len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "        \n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5ee76d",
   "metadata": {
    "papermill": {
     "duration": 0.010092,
     "end_time": "2023-04-13T11:11:11.778346",
     "exception": false,
     "start_time": "2023-04-13T11:11:11.768254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model - \n",
    "Contains the entire process explained earlier. As input it takes a batch of sentences and passes it through encoder to generate a context vector tensor for the entire batch. Then token by token it passes the sentence batch to decoder to generate output tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "677c95e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:11.800804Z",
     "iopub.status.busy": "2023-04-13T11:11:11.800181Z",
     "iopub.status.idle": "2023-04-13T11:11:11.809330Z",
     "shell.execute_reply": "2023-04-13T11:11:11.808338Z"
    },
    "papermill": {
     "duration": 0.023002,
     "end_time": "2023-04-13T11:11:11.811533",
     "exception": false,
     "start_time": "2023-04-13T11:11:11.788531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9793a156",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:11.833559Z",
     "iopub.status.busy": "2023-04-13T11:11:11.832770Z",
     "iopub.status.idle": "2023-04-13T11:11:11.838969Z",
     "shell.execute_reply": "2023-04-13T11:11:11.837913Z"
    },
    "papermill": {
     "duration": 0.01938,
     "end_time": "2023-04-13T11:11:11.841010",
     "exception": false,
     "start_time": "2023-04-13T11:11:11.821630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23165"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1aaa2cc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:11.863311Z",
     "iopub.status.busy": "2023-04-13T11:11:11.862459Z",
     "iopub.status.idle": "2023-04-13T11:11:11.868769Z",
     "shell.execute_reply": "2023-04-13T11:11:11.867744Z"
    },
    "papermill": {
     "duration": 0.019396,
     "end_time": "2023-04-13T11:11:11.870807",
     "exception": false,
     "start_time": "2023-04-13T11:11:11.851411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25528"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fr_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d6718",
   "metadata": {
    "papermill": {
     "duration": 0.010143,
     "end_time": "2023-04-13T11:11:11.891363",
     "exception": false,
     "start_time": "2023-04-13T11:11:11.881220",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc579b9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:11.913924Z",
     "iopub.status.busy": "2023-04-13T11:11:11.913024Z",
     "iopub.status.idle": "2023-04-13T11:11:13.243244Z",
     "shell.execute_reply": "2023-04-13T11:11:13.242167Z"
    },
    "papermill": {
     "duration": 1.344331,
     "end_time": "2023-04-13T11:11:13.246142",
     "exception": false,
     "start_time": "2023-04-13T11:11:11.901811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(en_vocab)\n",
    "OUTPUT_DIM = len(fr_vocab)\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "HID_DIM = 256\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c30312b",
   "metadata": {
    "papermill": {
     "duration": 0.010398,
     "end_time": "2023-04-13T11:11:13.267514",
     "exception": false,
     "start_time": "2023-04-13T11:11:13.257116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Initializing the model parameters\n",
    "Distribution used is taken from the github notebook(replicated the approach mentioned in the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28efa44f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:13.289745Z",
     "iopub.status.busy": "2023-04-13T11:11:13.289407Z",
     "iopub.status.idle": "2023-04-13T11:11:13.298395Z",
     "shell.execute_reply": "2023-04-13T11:11:13.297288Z"
    },
    "papermill": {
     "duration": 0.022513,
     "end_time": "2023-04-13T11:11:13.300479",
     "exception": false,
     "start_time": "2023-04-13T11:11:13.277966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(23165, 128)\n",
       "    (lstm): LSTM(128, 256, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(25528, 128)\n",
       "    (lstm): LSTM(128, 256, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=256, out_features=25528, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ac9c255",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:13.323194Z",
     "iopub.status.busy": "2023-04-13T11:11:13.322369Z",
     "iopub.status.idle": "2023-04-13T11:11:13.329028Z",
     "shell.execute_reply": "2023-04-13T11:11:13.327592Z"
    },
    "papermill": {
     "duration": 0.020075,
     "end_time": "2023-04-13T11:11:13.331099",
     "exception": false,
     "start_time": "2023-04-13T11:11:13.311024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 14,636,600 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ff9a23",
   "metadata": {
    "papermill": {
     "duration": 0.010334,
     "end_time": "2023-04-13T11:11:13.351873",
     "exception": false,
     "start_time": "2023-04-13T11:11:13.341539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Initializing optimizer and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "832d7080",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:13.374112Z",
     "iopub.status.busy": "2023-04-13T11:11:13.373830Z",
     "iopub.status.idle": "2023-04-13T11:11:13.378826Z",
     "shell.execute_reply": "2023-04-13T11:11:13.377750Z"
    },
    "papermill": {
     "duration": 0.018421,
     "end_time": "2023-04-13T11:11:13.380886",
     "exception": false,
     "start_time": "2023-04-13T11:11:13.362465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "TRG_PAD_IDX = fr_vocab['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bb404b",
   "metadata": {
    "papermill": {
     "duration": 0.010298,
     "end_time": "2023-04-13T11:11:13.401591",
     "exception": false,
     "start_time": "2023-04-13T11:11:13.391293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cc0b91b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:13.424621Z",
     "iopub.status.busy": "2023-04-13T11:11:13.423763Z",
     "iopub.status.idle": "2023-04-13T11:11:13.431448Z",
     "shell.execute_reply": "2023-04-13T11:11:13.430562Z"
    },
    "papermill": {
     "duration": 0.02148,
     "end_time": "2023-04-13T11:11:13.433537",
     "exception": false,
     "start_time": "2023-04-13T11:11:13.412057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for _, (src, trg) in enumerate(dataloader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / (len(dataloader)*BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64462ecf",
   "metadata": {
    "papermill": {
     "duration": 0.010381,
     "end_time": "2023-04-13T11:11:13.454434",
     "exception": false,
     "start_time": "2023-04-13T11:11:13.444053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Evaluation method - no gradient calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b9af969",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:13.477118Z",
     "iopub.status.busy": "2023-04-13T11:11:13.476303Z",
     "iopub.status.idle": "2023-04-13T11:11:13.483196Z",
     "shell.execute_reply": "2023-04-13T11:11:13.482269Z"
    },
    "papermill": {
     "duration": 0.020248,
     "end_time": "2023-04-13T11:11:13.485257",
     "exception": false,
     "start_time": "2023-04-13T11:11:13.465009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for _, (src, trg) in enumerate(dataloader):\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / (len(dataloader)*BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f13c5bb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:13.507935Z",
     "iopub.status.busy": "2023-04-13T11:11:13.507097Z",
     "iopub.status.idle": "2023-04-13T11:11:13.512369Z",
     "shell.execute_reply": "2023-04-13T11:11:13.511464Z"
    },
    "papermill": {
     "duration": 0.018638,
     "end_time": "2023-04-13T11:11:13.514456",
     "exception": false,
     "start_time": "2023-04-13T11:11:13.495818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fc98919",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:13.537121Z",
     "iopub.status.busy": "2023-04-13T11:11:13.536280Z",
     "iopub.status.idle": "2023-04-13T11:11:13.558302Z",
     "shell.execute_reply": "2023-04-13T11:11:13.557346Z"
    },
    "papermill": {
     "duration": 0.035606,
     "end_time": "2023-04-13T11:11:13.560544",
     "exception": false,
     "start_time": "2023-04-13T11:11:13.524938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del df_train\n",
    "del df_val\n",
    "del df_test\n",
    "del data\n",
    "del en_tokenizer\n",
    "del fr_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd576ed",
   "metadata": {
    "papermill": {
     "duration": 0.010378,
     "end_time": "2023-04-13T11:11:13.581633",
     "exception": false,
     "start_time": "2023-04-13T11:11:13.571255",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ae1188e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:13.603766Z",
     "iopub.status.busy": "2023-04-13T11:11:13.603450Z",
     "iopub.status.idle": "2023-04-13T11:11:13.607508Z",
     "shell.execute_reply": "2023-04-13T11:11:13.606541Z"
    },
    "papermill": {
     "duration": 0.01752,
     "end_time": "2023-04-13T11:11:13.609615",
     "exception": false,
     "start_time": "2023-04-13T11:11:13.592095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = 'enc-dec-basic1-model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a63160dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:11:13.632083Z",
     "iopub.status.busy": "2023-04-13T11:11:13.631527Z",
     "iopub.status.idle": "2023-04-13T12:19:35.291985Z",
     "shell.execute_reply": "2023-04-13T12:19:35.290853Z"
    },
    "papermill": {
     "duration": 4101.685271,
     "end_time": "2023-04-13T12:19:35.305361",
     "exception": false,
     "start_time": "2023-04-13T11:11:13.620090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 13m 42s\n",
      "\tTrain Loss: 0.779 | Train PPL:   2.179\n",
      "\t Val. Loss: 0.778 |  Val. PPL:   2.177\n",
      "Epoch: 02 | Time: 13m 36s\n",
      "\tTrain Loss: 0.700 | Train PPL:   2.014\n",
      "\t Val. Loss: 0.769 |  Val. PPL:   2.157\n",
      "Epoch: 03 | Time: 13m 38s\n",
      "\tTrain Loss: 0.663 | Train PPL:   1.941\n",
      "\t Val. Loss: 0.761 |  Val. PPL:   2.140\n",
      "Epoch: 04 | Time: 13m 42s\n",
      "\tTrain Loss: 0.637 | Train PPL:   1.891\n",
      "\t Val. Loss: 0.745 |  Val. PPL:   2.107\n",
      "Epoch: 05 | Time: 13m 40s\n",
      "\tTrain Loss: 0.617 | Train PPL:   1.854\n",
      "\t Val. Loss: 0.738 |  Val. PPL:   2.092\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, val_loader, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57eb1e83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T12:19:35.329457Z",
     "iopub.status.busy": "2023-04-13T12:19:35.328584Z",
     "iopub.status.idle": "2023-04-13T12:19:52.804301Z",
     "shell.execute_reply": "2023-04-13T12:19:52.802734Z"
    },
    "papermill": {
     "duration": 17.489869,
     "end_time": "2023-04-13T12:19:52.806559",
     "exception": false,
     "start_time": "2023-04-13T12:19:35.316690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.740 | Test PPL:   2.096 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "test_loss = evaluate(model, test_loader, criterion)\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b81cb8e",
   "metadata": {
    "papermill": {
     "duration": 0.011009,
     "end_time": "2023-04-13T12:19:52.829077",
     "exception": false,
     "start_time": "2023-04-13T12:19:52.818068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4236.10325,
   "end_time": "2023-04-13T12:19:56.033916",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-13T11:09:19.930666",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
