{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8a7c6f7",
   "metadata": {
    "papermill": {
     "duration": 0.009307,
     "end_time": "2023-04-13T11:08:50.044152",
     "exception": false,
     "start_time": "2023-04-13T11:08:50.034845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This is an implementation for Sequence to Sequence Encoder - Decoder Model (with Attention) using GRU trained for the task of English-French translations. It is based on the paper - [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473) and the notebook [Pytorch Seq2Seq - RNN with Attention](https://github.com/SethHWeidman/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb). \n",
    "\n",
    "It is implemented as an excerise to gain a deeper understanding of Encoder - Decoder models and build on it to explore advancements on the same. The notebook is a followup to the first notebook which used 2 layer LSTM Encoder-Decoder model for translation English sentences to French.\n",
    "\n",
    "Dataset used - [English - French Translations](https://www.kaggle.com/datasets/dhruvildave/en-fr-translation-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cab09a",
   "metadata": {
    "papermill": {
     "duration": 0.008187,
     "end_time": "2023-04-13T11:08:50.060580",
     "exception": false,
     "start_time": "2023-04-13T11:08:50.052393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Drawback of Notebook 1 - RNN Encoder - Decoder\n",
    "In the previous notebook we used 2 layer LSTM Encoder-Decoder model. \n",
    "The main drawback of such an architecture is that all the information from the starting of the sentence to the end has to be crammed into a single context vector calculated as the final hidden state of the sentence pass through encoder. \n",
    "This leads to 3 effects - \n",
    "1. A single vector most of the time proves insufficient to capture context of the whole sentence, specially longer sentences.\n",
    "2. Information from tokens at the beginning of the sentence goes through multiple non-linear operations, while ones at the end are processed through few operations. Hence, there is an unevenness in processing of tokens.\n",
    "3. Further, when this context vector is passed through the decoder units, initial token pass have much more info about the source sentence compared to later tokens. This is because, decoding process of later tokens have info about the last hidden state which packs info about all of the previously generated tokens along with the initial context vector.\n",
    "\n",
    "Certain improvements were implemented in the paper - [Learning Phrase Representations - RNN Encoder Decoder](https://arxiv.org/abs/1406.1078), where the context vector from the encoder is fed as input to each token pass in the decoder along with the previous hidden state to provide with more info about the source sentence.\n",
    "\n",
    "Along with the above, the attention mechanism discussed in the referenced material utilises the final outputs of the whole sentence (one vector for each token), so that each decoder pass for a token has information about the whole sentence.\n",
    "\n",
    "Another mechanism utilised in this notebook is bidirectional RNN, which basically processes the sentence token by token in both the directions. This is equivalent to adding another RNN layer with inputs reversed. Pytorch internally configures this without any extra effort with just another parameter bidirectional=True."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038190bd",
   "metadata": {
    "papermill": {
     "duration": 0.008071,
     "end_time": "2023-04-13T11:08:50.076701",
     "exception": false,
     "start_time": "2023-04-13T11:08:50.068630",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "477a4841",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-13T11:08:50.095326Z",
     "iopub.status.busy": "2023-04-13T11:08:50.094858Z",
     "iopub.status.idle": "2023-04-13T11:09:13.223763Z",
     "shell.execute_reply": "2023-04-13T11:09:13.222643Z"
    },
    "papermill": {
     "duration": 23.142132,
     "end_time": "2023-04-13T11:09:13.227160",
     "exception": false,
     "start_time": "2023-04-13T11:08:50.085028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/en-fr-translation-dataset/en-fr.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from string import digits\n",
    "import random\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import torch\n",
    "import torchtext\n",
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d60e52f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:09:13.260371Z",
     "iopub.status.busy": "2023-04-13T11:09:13.259437Z",
     "iopub.status.idle": "2023-04-13T11:09:13.276359Z",
     "shell.execute_reply": "2023-04-13T11:09:13.274862Z"
    },
    "papermill": {
     "duration": 0.040526,
     "end_time": "2023-04-13T11:09:13.279294",
     "exception": false,
     "start_time": "2023-04-13T11:09:13.238768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 97\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bca04ad",
   "metadata": {
    "papermill": {
     "duration": 0.011303,
     "end_time": "2023-04-13T11:09:13.311312",
     "exception": false,
     "start_time": "2023-04-13T11:09:13.300009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Downloading Spacy models for use as tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b1be8d0",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-04-13T11:09:13.351992Z",
     "iopub.status.busy": "2023-04-13T11:09:13.350483Z",
     "iopub.status.idle": "2023-04-13T11:10:04.401282Z",
     "shell.execute_reply": "2023-04-13T11:10:04.399871Z"
    },
    "papermill": {
     "duration": 51.077512,
     "end_time": "2023-04-13T11:10:04.404307",
     "exception": false,
     "start_time": "2023-04-13T11:09:13.326795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /opt/conda/lib/python3.7/site-packages (from en-core-web-sm==3.5.0) (3.5.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.21.6)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.4)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\r\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\r\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (59.8.0)\r\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\r\n",
      "Requirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.11.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.14)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.11.4)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_sm')\r\n",
      "Collecting fr-core-news-sm==3.5.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.5.0/fr_core_news_sm-3.5.0-py3-none-any.whl (16.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /opt/conda/lib/python3.7/site-packages (from fr-core-news-sm==3.5.0) (3.5.1)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.0.8)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (59.8.0)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.1.1)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (4.64.1)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.10.4)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.28.2)\r\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.7.0)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.4.6)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.1.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (23.0)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.21.6)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.3.0)\r\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.10.1)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.0.7)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (6.3.0)\r\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (8.1.9)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.0.4)\r\n",
      "Requirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (4.4.0)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.0.9)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.0.8)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.0.12)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.11.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.26.14)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2022.12.7)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.0.4)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.7.9)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (8.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.1.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (4.11.4)\r\n",
      "Installing collected packages: fr-core-news-sm\r\n",
      "Successfully installed fr-core-news-sm-3.5.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\r\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf4e489",
   "metadata": {
    "papermill": {
     "duration": 0.010367,
     "end_time": "2023-04-13T11:10:04.425749",
     "exception": false,
     "start_time": "2023-04-13T11:10:04.415382",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data import\n",
    "Reading only 50000 rows for demonstration purposes. Training RNN is slow as it it takes input tokens one by one and I am limited by the compute available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b6483e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:04.448627Z",
     "iopub.status.busy": "2023-04-13T11:10:04.448284Z",
     "iopub.status.idle": "2023-04-13T11:10:04.750838Z",
     "shell.execute_reply": "2023-04-13T11:10:04.749644Z"
    },
    "papermill": {
     "duration": 0.316799,
     "end_time": "2023-04-13T11:10:04.753144",
     "exception": false,
     "start_time": "2023-04-13T11:10:04.436345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Changing Lives | Changing Society | How It Wor...</td>\n",
       "      <td>Il a transformé notre vie | Il a transformé la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Site map</td>\n",
       "      <td>Plan du site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feedback</td>\n",
       "      <td>Rétroaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Credits</td>\n",
       "      <td>Crédits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Français</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0  Changing Lives | Changing Society | How It Wor...   \n",
       "1                                           Site map   \n",
       "2                                           Feedback   \n",
       "3                                            Credits   \n",
       "4                                           Français   \n",
       "\n",
       "                                                  fr  \n",
       "0  Il a transformé notre vie | Il a transformé la...  \n",
       "1                                       Plan du site  \n",
       "2                                        Rétroaction  \n",
       "3                                            Crédits  \n",
       "4                                            English  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/en-fr-translation-dataset/en-fr.csv', nrows=30000)\n",
    "data = data.dropna().drop_duplicates()\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c67696",
   "metadata": {
    "papermill": {
     "duration": 0.010608,
     "end_time": "2023-04-13T11:10:04.775305",
     "exception": false,
     "start_time": "2023-04-13T11:10:04.764697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Initializing the tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5861b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:04.797813Z",
     "iopub.status.busy": "2023-04-13T11:10:04.797483Z",
     "iopub.status.idle": "2023-04-13T11:10:11.180575Z",
     "shell.execute_reply": "2023-04-13T11:10:11.179521Z"
    },
    "papermill": {
     "duration": 6.397595,
     "end_time": "2023-04-13T11:10:11.183483",
     "exception": false,
     "start_time": "2023-04-13T11:10:04.785888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fr_tokenizer = get_tokenizer('spacy', language='fr_core_news_sm')\n",
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0807b64b",
   "metadata": {
    "papermill": {
     "duration": 0.010416,
     "end_time": "2023-04-13T11:10:11.204810",
     "exception": false,
     "start_time": "2023-04-13T11:10:11.194394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Splitting train, test and val datasets\n",
    "Train - 85%, Val - 10%, Test - 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d682fb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:11.227057Z",
     "iopub.status.busy": "2023-04-13T11:10:11.226739Z",
     "iopub.status.idle": "2023-04-13T11:10:11.250351Z",
     "shell.execute_reply": "2023-04-13T11:10:11.249218Z"
    },
    "papermill": {
     "duration": 0.037289,
     "end_time": "2023-04-13T11:10:11.252550",
     "exception": false,
     "start_time": "2023-04-13T11:10:11.215261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of train:  25500\n",
      "len of val:  2999\n",
      "len of test:  1500\n"
     ]
    }
   ],
   "source": [
    "val_frac = 0.1\n",
    "test_frac = 0.05\n",
    "val_split_idx = int(len(data)*val_frac)\n",
    "test_split_idx = int(len(data)*(val_frac + test_frac))\n",
    "data_idx = list(range(len(data)))\n",
    "np.random.shuffle(data_idx)\n",
    "\n",
    "val_idx, test_idx, train_idx = data_idx[:val_split_idx], data_idx[val_split_idx:test_split_idx], data_idx[test_split_idx:]\n",
    "print('len of train: ', len(train_idx))\n",
    "print('len of val: ', len(val_idx))\n",
    "print('len of test: ', len(test_idx))\n",
    "\n",
    "df_train = data.iloc[train_idx].reset_index().drop('index',axis=1)\n",
    "df_test = data.iloc[test_idx].reset_index().drop('index',axis=1)\n",
    "df_val = data.iloc[val_idx].reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "592256ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:11.275457Z",
     "iopub.status.busy": "2023-04-13T11:10:11.274653Z",
     "iopub.status.idle": "2023-04-13T11:10:11.281081Z",
     "shell.execute_reply": "2023-04-13T11:10:11.280217Z"
    },
    "papermill": {
     "duration": 0.020004,
     "end_time": "2023-04-13T11:10:11.283131",
     "exception": false,
     "start_time": "2023-04-13T11:10:11.263127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_vocab(data, source_tokenizer, target_tokenizer):\n",
    "    en_counter = Counter()\n",
    "    fr_counter = Counter()\n",
    "    translations = data.values.tolist()\n",
    "    for translation in translations:\n",
    "        en_counter.update(source_tokenizer(translation[0]))\n",
    "        fr_counter.update(target_tokenizer(translation[1]))\n",
    "    return vocab(en_counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'], min_freq=5), vocab(fr_counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'], min_freq=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414afc1e",
   "metadata": {
    "papermill": {
     "duration": 0.010376,
     "end_time": "2023-04-13T11:10:11.303936",
     "exception": false,
     "start_time": "2023-04-13T11:10:11.293560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Building separate vocabs for English & French\n",
    "Note: Using only training data to build the vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98759ce0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:11.327289Z",
     "iopub.status.busy": "2023-04-13T11:10:11.326356Z",
     "iopub.status.idle": "2023-04-13T11:10:19.020597Z",
     "shell.execute_reply": "2023-04-13T11:10:19.019519Z"
    },
    "papermill": {
     "duration": 7.708989,
     "end_time": "2023-04-13T11:10:19.023527",
     "exception": false,
     "start_time": "2023-04-13T11:10:11.314538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_vocab, fr_vocab = build_vocab(df_train, en_tokenizer, fr_tokenizer)\n",
    "en_vocab.set_default_index(en_vocab['<unk>'])\n",
    "fr_vocab.set_default_index(fr_vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bab11ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:19.047272Z",
     "iopub.status.busy": "2023-04-13T11:10:19.046955Z",
     "iopub.status.idle": "2023-04-13T11:10:19.053295Z",
     "shell.execute_reply": "2023-04-13T11:10:19.052198Z"
    },
    "papermill": {
     "duration": 0.02106,
     "end_time": "2023-04-13T11:10:19.055852",
     "exception": false,
     "start_time": "2023-04-13T11:10:19.034792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_process(data):\n",
    "    translations = data.values.tolist()\n",
    "    pairs = []\n",
    "    for translation in translations:\n",
    "        en_tensor = torch.tensor([en_vocab[token] for token in en_tokenizer(translation[0])],\n",
    "                            dtype=torch.long)\n",
    "        fr_tensor = torch.tensor([fr_vocab[token] for token in fr_tokenizer(translation[1])],\n",
    "                            dtype=torch.long)\n",
    "        pairs.append((en_tensor, fr_tensor))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7786e515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:19.079432Z",
     "iopub.status.busy": "2023-04-13T11:10:19.078571Z",
     "iopub.status.idle": "2023-04-13T11:10:25.336918Z",
     "shell.execute_reply": "2023-04-13T11:10:25.335841Z"
    },
    "papermill": {
     "duration": 6.272904,
     "end_time": "2023-04-13T11:10:25.339758",
     "exception": false,
     "start_time": "2023-04-13T11:10:19.066854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = data_process(df_train)\n",
    "val_data = data_process(df_val)\n",
    "test_data = data_process(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17da11db",
   "metadata": {
    "papermill": {
     "duration": 0.010445,
     "end_time": "2023-04-13T11:10:25.361231",
     "exception": false,
     "start_time": "2023-04-13T11:10:25.350786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Note:\n",
    "Keeping a small batch size due to limitation of GPU size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e73d261",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:25.385047Z",
     "iopub.status.busy": "2023-04-13T11:10:25.384141Z",
     "iopub.status.idle": "2023-04-13T11:10:25.390269Z",
     "shell.execute_reply": "2023-04-13T11:10:25.389158Z"
    },
    "papermill": {
     "duration": 0.020082,
     "end_time": "2023-04-13T11:10:25.392372",
     "exception": false,
     "start_time": "2023-04-13T11:10:25.372290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "PAD_IDX = en_vocab['<pad>']\n",
    "BOS_IDX = en_vocab['<bos>']\n",
    "EOS_IDX = en_vocab['<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fbfff75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:25.414878Z",
     "iopub.status.busy": "2023-04-13T11:10:25.414304Z",
     "iopub.status.idle": "2023-04-13T11:10:25.421341Z",
     "shell.execute_reply": "2023-04-13T11:10:25.420424Z"
    },
    "papermill": {
     "duration": 0.020228,
     "end_time": "2023-04-13T11:10:25.423237",
     "exception": false,
     "start_time": "2023-04-13T11:10:25.403009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_batch(data_batch):\n",
    "    en_batch, fr_batch = [], []\n",
    "    for (en_item, fr_item) in data_batch:\n",
    "        en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0).to(device))\n",
    "        fr_batch.append(torch.cat([torch.tensor([BOS_IDX]), fr_item, torch.tensor([EOS_IDX])], dim=0).to(device))  \n",
    "        \n",
    "    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
    "    fr_batch = pad_sequence(fr_batch, padding_value=PAD_IDX)\n",
    "    return en_batch, fr_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3571498a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:25.446627Z",
     "iopub.status.busy": "2023-04-13T11:10:25.445795Z",
     "iopub.status.idle": "2023-04-13T11:10:25.451724Z",
     "shell.execute_reply": "2023-04-13T11:10:25.450809Z"
    },
    "papermill": {
     "duration": 0.019798,
     "end_time": "2023-04-13T11:10:25.453815",
     "exception": false,
     "start_time": "2023-04-13T11:10:25.434017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919d620e",
   "metadata": {
    "papermill": {
     "duration": 0.01044,
     "end_time": "2023-04-13T11:10:25.474708",
     "exception": false,
     "start_time": "2023-04-13T11:10:25.464268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Encoder process -\n",
    "The encoder process is similar to the previous notebook with few additions. \n",
    "1. Bidirectional processing - RNN processes the input in both the directions (first to last word and last word to first).\n",
    "2. Bidirectional processing increases the size of the hidden vector by the magnitude of 2 (hidden vetor - [forward hidden vectors, backward hidden vectors]). This vector needs to be mapped to the decoder input hidden vector shape. For this a linear_layer maps from enc_hidden_vector*2 -> dec_hidden_vector. \n",
    "3. Both the output from the linear_layer discussed above and the final ouptus of all the tokens are taken are returned from the encoder.\n",
    "\n",
    "example pseudocode for one sentence pass through the encoder - \n",
    "\n",
    "<code>\n",
    "    vocab = build_vocab(source_sentence)\n",
    "    sentence_tensor = [vocab[tokenize(word)] for word in source_sentence.split(' ')]\n",
    "    hidden = 0\n",
    "    for word_tensor in sentence_tensor:\n",
    "        emb_vector = embed(word_tensor)\n",
    "        [hidden_forward, hidden_backward], output = rnn_unit(emb_vector, hidden) # for 1 layer\n",
    "        # for multiple layers, hidden state are stacked on top of each other -> [forward1, backward1, forward2, backward2..]\n",
    "        # output = [forwardLast, backwardLast]\n",
    "        hidden = [hidden_forward, hidden_backward]\n",
    "    context = linear_layer(concat(hidden[-2], hidden[-1])) # output is size of decoder hidden input\n",
    "</code>\n",
    "\n",
    "#### Inputs\n",
    "* input_dim - source sentence vocab size\n",
    "* emb_dim - output size of embedding layer\n",
    "* enc_hid_dim - Output size of hidden vector generated by RNN unit (actual output would have this size X 2 for bidirectional usecase)\n",
    "* dec_hid_dim - Size of decoder hidden dimension to be used for transforming final encoder hidden state to decoder initial hidden state through a linear layer.\n",
    "* dropout - percentage of droput to be used to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c65644e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:25.497169Z",
     "iopub.status.busy": "2023-04-13T11:10:25.496900Z",
     "iopub.status.idle": "2023-04-13T11:10:25.505514Z",
     "shell.execute_reply": "2023-04-13T11:10:25.504531Z"
    },
    "papermill": {
     "duration": 0.022347,
     "end_time": "2023-04-13T11:10:25.507573",
     "exception": false,
     "start_time": "2023-04-13T11:10:25.485226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim: int, \n",
    "                 emb_dim: int, \n",
    "                 enc_hid_dim: int, \n",
    "                 dec_hid_dim: int, \n",
    "                 dropout: float):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.gru = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src sent len, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src sent len, batch size, emb dim] \n",
    "        # each token is converted into an embedding vector of size emb_dim\n",
    "        \n",
    "        outputs, hidden = self.gru(embedded)\n",
    "                \n",
    "        #outputs = [src sent len, batch size, hid dim * num directions] last layer output of gru\n",
    "        #hidden = [n layers * num directions, batch size, hid dim] hidden state output of last token pass through gru\n",
    "        \n",
    "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        \n",
    "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
    "        #  encoder RNNs fed through a linear layer\n",
    "        \n",
    "        # here hidden[-2,:,:] = forward rnn last hidden state, hidden[-1,:,:] = backward rnn last hidden state\n",
    "        # here we have only one layer, in case of multiple layers the hidden states are further stacked\n",
    "        \n",
    "        # Note: torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        # is of shape [batch_size, enc_hid_dim * 2]\n",
    "        \n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
    "        \n",
    "        #tanh is applied to keep the results in the range [-1, 1]\n",
    "        #outputs = [src sent len, batch size, enc hid dim * 2]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        \n",
    "        return outputs, hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c83a6af",
   "metadata": {
    "papermill": {
     "duration": 0.010425,
     "end_time": "2023-04-13T11:10:25.528579",
     "exception": false,
     "start_time": "2023-04-13T11:10:25.518154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Attention process - \n",
    "1. Takes in outputs and final hidden state of encoder (passed through linear layer).\n",
    "2. Outputs shape - [1, sent_len, enc_hidden_size * 2] multiplied by 2 for forward and backward\n",
    "3. Hidden shape - [1, dec_hidden_state]\n",
    "4. Repeat hidden state sent_len times and concatenate outputs and hidden shape.\n",
    "5. Pass through a linear layer to map to an attention vector.\n",
    "6. Attention vector is used in the decoder to calculated weighted sum of encoder outputs to be used in decoder RNN unit for token prediction. This helps decoder learn to attend to different parts of the whole source sentence important to the token generation.\n",
    "\n",
    "<code>\n",
    "    inputs -> encoder_outputs, hidden\n",
    "    hidden_repeated = repeat(hidden, sent_len)\n",
    "    attention_input = concat(encoder_outputs, hidden_repeated)\n",
    "    attention_vector = linear_layer(attention_input)\n",
    "    # attention vector size -> [1, sent_len, attention_dim]\n",
    "    # we need to transform it to [1, sent_len]\n",
    "    attention_vector = transform(attention_vector) # either by summing across last dimension or through mat mul with a randomly initialized vector that can be trained\n",
    "    return attention_vector\n",
    " </code>\n",
    " \n",
    "#### Inputs\n",
    "* enc_hid_dim = hidden dimension of encoder rnn unit\n",
    "* dec_hid_dim = hidden dimension of decoder rnn unit\n",
    "* attn_dim = dimension of attention vector to be generated by the attention unit.\n",
    "\n",
    "Note: -\n",
    "Using summation approach here to reduce dimension of attention vector from [batch_size, src_len, attn_dim] to [batch_size, attn_len] to reduce training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a74cd6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:25.551316Z",
     "iopub.status.busy": "2023-04-13T11:10:25.550413Z",
     "iopub.status.idle": "2023-04-13T11:10:25.559772Z",
     "shell.execute_reply": "2023-04-13T11:10:25.558881Z"
    },
    "papermill": {
     "duration": 0.022742,
     "end_time": "2023-04-13T11:10:25.561814",
     "exception": false,
     "start_time": "2023-04-13T11:10:25.539072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, \n",
    "                 enc_hid_dim: int, \n",
    "                 dec_hid_dim: int,\n",
    "                 attn_dim: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n",
    "        \n",
    "        self.attn = nn.Linear(self.attn_in, attn_dim)\n",
    "        # self.v = nn.Parameter(torch.rand(attn_dim))\n",
    "        \n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        \n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        #repeat decoder hidden state src_len times\n",
    "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #decoder_hidden = [batch size, src sent len, dec hid dim]\n",
    "        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n",
    "        \n",
    "        # attention layer takes encoder_outpts and decoder_hidden concatenated together.\n",
    "        # Hence, the need of repeating decoder_hidden sent_len times as the encoder_outputs are sent_len long\n",
    "        \n",
    "        # concatenate along last dim and feed through attention layer\n",
    "        # apply tanh for restricting values to [-1, 1]\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((\n",
    "            repeated_decoder_hidden, \n",
    "            encoder_outputs), \n",
    "            dim = 2))) \n",
    "        \n",
    "        attention = torch.sum(energy, dim=2)\n",
    "        \n",
    "        #energy = [batch size, src sent len, attn_dim]\n",
    "        \n",
    "        #v = [attn_dim] is used to reduce dimensionality of energy vector for each sent_token\n",
    "        # currently each sent_token's attn vector is attn_dim long. \n",
    "        # We need to reduce it to 1 value for each sentence_token\n",
    "        \n",
    "        #here we learn a parameter v, it can be done by summing through the last dim as well for energy vector\n",
    "        \n",
    "        ### energy = energy.permute(0, 2, 1)\n",
    "        \n",
    "        #energy = [batch size, attn_dim, src sent len]\n",
    "        \n",
    "        ### v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
    "        #v = [batch size, 1, attn_dim]\n",
    "        \n",
    "        # batch matrix mul with v will transform energy to size - [batch size, 1, src_len]\n",
    "        ### attention = torch.bmm(v, energy).squeeze(1)\n",
    "        #attention= [batch size, src len]\n",
    "        \n",
    "        # at the end we have one number for each token in a sentence in attention vector.\n",
    "        # this will be used to calculate the weighted attention vector in decoder.\n",
    "        \n",
    "        return torch.nn.functional.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b605c6ca",
   "metadata": {
    "papermill": {
     "duration": 0.010516,
     "end_time": "2023-04-13T11:10:25.582791",
     "exception": false,
     "start_time": "2023-04-13T11:10:25.572275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Decoder process - \n",
    "The decoder process is similar to the previous step, except few changes.\n",
    "1. The decoder layer contains the attention layer anduses the output and hidden state returned by encoder to generate attention vector.\n",
    "2. It performs matrix multiplication of encoder output vector with attention vector to generate weighted attention.\n",
    "3. Weighted attention vector along with previous hidden state and embedding of previous token is passed as input to rnn unit. \n",
    "4. Output generated by the rnn unit along with weighted attention vector and embedding vector for the previous token is passed to linear_layer to generate the final output probability distribution. Argmax is taken to get the output index from the target vocab.\n",
    "\n",
    "example pseudocode for one sentence pass through decoder - \n",
    "\n",
    "<code>\n",
    "    vocab = build_vocab(target_sentence)\n",
    "    sentence_tensor = [vocab[tokenize(word)] for word in target_sentence.split(' ')]\n",
    "    hidden = hidden state from encoder\n",
    "    word_tensor = sentence_tensor[0]\n",
    "    predicted_sentence = []\n",
    "    for i in range(len(sentence_tensor)):\n",
    "        emb_vector = embed(word_tensor)\n",
    "        attention_vector = attention(hidden, encoder_outputs)\n",
    "        weighted_attention = attention_vetor * encoder_outputs\n",
    "        hidden, output = rnn_unit(concat(weighted_attention, emb_vector), hidden) # hidden = output for 1 layer rnn\n",
    "        prediction = argmax(linear_layer(concat(emb_vector, weighted_attention, output)))\n",
    "        word_tensor = prediction\n",
    "        predicted_sentence.append(prediction)\n",
    "</code>\n",
    "\n",
    "\n",
    "#### Inputs \n",
    "* output_dim = target vocab size\n",
    "* emb_dim = embedding size\n",
    "* enc_hid_dim = size of encoder rnn unit hidden state\n",
    "* dec_hid_dim = size of decoder rnn unit hidden state\n",
    "* dropout = for avoiding overfitting\n",
    "* attention = attention module object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a008dbfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:25.605405Z",
     "iopub.status.busy": "2023-04-13T11:10:25.605144Z",
     "iopub.status.idle": "2023-04-13T11:10:25.617133Z",
     "shell.execute_reply": "2023-04-13T11:10:25.616172Z"
    },
    "papermill": {
     "duration": 0.026222,
     "end_time": "2023-04-13T11:10:25.619543",
     "exception": false,
     "start_time": "2023-04-13T11:10:25.593321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 output_dim: int, \n",
    "                 emb_dim: int, \n",
    "                 enc_hid_dim: int, \n",
    "                 dec_hid_dim: int, \n",
    "                 dropout: int, \n",
    "                 attention: nn.Module):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout = dropout\n",
    "        self.attention = attention\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.gru = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "        # self.attention.attn_in = (enc_hid_dim*2) + dec_hid_dim\n",
    "        self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def _weighted_encoder_rep(self, decoder_hidden, encoder_outputs):\n",
    "        \n",
    "        # Outputs a vector summing to 1 of length seq_len for each observation\n",
    "        a = self.attention(decoder_hidden, encoder_outputs)\n",
    "\n",
    "        #a = [batch size, src len]\n",
    "        a = a.unsqueeze(1)\n",
    "        #a = [batch size, 1, src len]\n",
    "\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n",
    "\n",
    "        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
    "        # batch matrix mul of encoder_outputs and attention vector\n",
    "        # essentially this step's output helps the decoder gather context from the entire sentence\n",
    "        \n",
    "        #weighted_encoder_rep = [batch size, 1, enc hid dim * 2]\n",
    "        weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n",
    "        #weighted_encoder_rep = [1, batch size, enc hid dim * 2]\n",
    "        \n",
    "        return weighted_encoder_rep\n",
    "        \n",
    "        \n",
    "    def forward(self, input, decoder_hidden, encoder_outputs):\n",
    "             \n",
    "        #input = [batch size] Note: \"one word(token) at a time\"\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        #embedded = [1, batch size, emb dim]\n",
    "        \n",
    "        weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden, \n",
    "                                                          encoder_outputs)\n",
    "        \n",
    "        # Then, the input to the decoder for the current token is a concatenation of:\n",
    "        # the weighted attention calculated from encoder outputs and attention vector and\n",
    "        # The embedding itself\n",
    "        # Decoder hidden state is fed separately without concatenating\n",
    "        # earlier we used to only use the embedding along with the decoder hidden state\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n",
    "        \n",
    "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
    "        output, decoder_hidden = self.gru(rnn_input, decoder_hidden.unsqueeze(0))\n",
    "        \n",
    "        #output = [sent len, batch size, dec hid dim * n directions] 1 direction in this case\n",
    "        # sent len is 1 as we pass token by token \n",
    "        # so output size is [1, batch size, dec_hid_dim]\n",
    "        \n",
    "        #decoder_hidden = [n layers * n directions, batch size, dec hid dim]\n",
    "\n",
    "        #output = [1, batch size, dec hid dim]\n",
    "        #hidden = [1, batch size, dec hid dim]\n",
    "        #this also means that output == hidden\n",
    "        assert (output == decoder_hidden).all()\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
    "        \n",
    "        # output is fed tho\n",
    "        output = self.out(torch.cat((output, \n",
    "                                     weighted_encoder_rep, \n",
    "                                     embedded), dim = 1))\n",
    "        \n",
    "        #output = [batch size, output dim]\n",
    "        \n",
    "        return output, decoder_hidden.squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28685aa4",
   "metadata": {
    "papermill": {
     "duration": 0.010279,
     "end_time": "2023-04-13T11:10:25.640253",
     "exception": false,
     "start_time": "2023-04-13T11:10:25.629974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model \n",
    "1. Sentence is passed through the encoder and the encoder outputs and last hidden state is received as output.\n",
    "2. The above received values are passed through decoder along with one token at a time for the entire batch.\n",
    "3. output and the hidden state is received as output. output is used to generate the token by taking max and hidden is used for the next token generation.\n",
    "4. The whole process is followed in a loop for all the tokens in the target sentence.\n",
    "5. Teacher forcing is used for better training. It basically uses the actual target token instead of the generated token from the model for the next rnn decoder step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "addc33d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:25.662240Z",
     "iopub.status.busy": "2023-04-13T11:10:25.661971Z",
     "iopub.status.idle": "2023-04-13T11:10:25.670137Z",
     "shell.execute_reply": "2023-04-13T11:10:25.669162Z"
    },
    "papermill": {
     "duration": 0.021458,
     "end_time": "2023-04-13T11:10:25.672162",
     "exception": false,
     "start_time": "2023-04-13T11:10:25.650704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, \n",
    "                 encoder: nn.Module, \n",
    "                 decoder: nn.Module, \n",
    "                 device: torch.device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, \n",
    "                teacher_forcing_ratio: float = 0.5):\n",
    "        \n",
    "        #src = [src sent len, batch size]\n",
    "        #trg = [trg sent len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
    "        \n",
    "        batch_size = src.shape[1]\n",
    "        max_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "                \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        output = trg[0,:]\n",
    "        \n",
    "        for t in range(1, max_len):\n",
    "            output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.max(1)[1]\n",
    "            output = (trg[t] if teacher_force else top1)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3cfc7d",
   "metadata": {
    "papermill": {
     "duration": 0.010339,
     "end_time": "2023-04-13T11:10:25.692925",
     "exception": false,
     "start_time": "2023-04-13T11:10:25.682586",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e058846e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:25.715594Z",
     "iopub.status.busy": "2023-04-13T11:10:25.714817Z",
     "iopub.status.idle": "2023-04-13T11:10:26.863378Z",
     "shell.execute_reply": "2023-04-13T11:10:26.862305Z"
    },
    "papermill": {
     "duration": 1.162404,
     "end_time": "2023-04-13T11:10:26.865971",
     "exception": false,
     "start_time": "2023-04-13T11:10:25.703567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(en_vocab)\n",
    "OUTPUT_DIM = len(fr_vocab)\n",
    "ENC_EMB_DIM = 64\n",
    "DEC_EMB_DIM = 64\n",
    "ENC_HID_DIM = 128\n",
    "DEC_HID_DIM = 128\n",
    "ATTN_DIM = 32\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69e5595b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:26.889503Z",
     "iopub.status.busy": "2023-04-13T11:10:26.888522Z",
     "iopub.status.idle": "2023-04-13T11:10:26.895595Z",
     "shell.execute_reply": "2023-04-13T11:10:26.894533Z"
    },
    "papermill": {
     "duration": 0.020792,
     "end_time": "2023-04-13T11:10:26.897699",
     "exception": false,
     "start_time": "2023-04-13T11:10:26.876907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8560, 9249)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_vocab), len(fr_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f7d67a",
   "metadata": {
    "papermill": {
     "duration": 0.01035,
     "end_time": "2023-04-13T11:10:26.918567",
     "exception": false,
     "start_time": "2023-04-13T11:10:26.908217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Initializing the model parameters with a distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa502d37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:26.940894Z",
     "iopub.status.busy": "2023-04-13T11:10:26.940624Z",
     "iopub.status.idle": "2023-04-13T11:10:26.951404Z",
     "shell.execute_reply": "2023-04-13T11:10:26.950373Z"
    },
    "papermill": {
     "duration": 0.024401,
     "end_time": "2023-04-13T11:10:26.953509",
     "exception": false,
     "start_time": "2023-04-13T11:10:26.929108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(8560, 64)\n",
       "    (gru): GRU(64, 128, bidirectional=True)\n",
       "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=384, out_features=32, bias=True)\n",
       "    )\n",
       "    (embedding): Embedding(9249, 64)\n",
       "    (gru): GRU(320, 128)\n",
       "    (out): Linear(in_features=448, out_features=9249, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m: nn.Module):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "065c260e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:26.976656Z",
     "iopub.status.busy": "2023-04-13T11:10:26.975770Z",
     "iopub.status.idle": "2023-04-13T11:10:26.982306Z",
     "shell.execute_reply": "2023-04-13T11:10:26.981217Z"
    },
    "papermill": {
     "duration": 0.020121,
     "end_time": "2023-04-13T11:10:26.984391",
     "exception": false,
     "start_time": "2023-04-13T11:10:26.964270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 5,659,585 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2141490e",
   "metadata": {
    "papermill": {
     "duration": 0.010599,
     "end_time": "2023-04-13T11:10:27.005610",
     "exception": false,
     "start_time": "2023-04-13T11:10:26.995011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Initializer optimizer and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "046c2642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:27.028617Z",
     "iopub.status.busy": "2023-04-13T11:10:27.027820Z",
     "iopub.status.idle": "2023-04-13T11:10:27.033268Z",
     "shell.execute_reply": "2023-04-13T11:10:27.032387Z"
    },
    "papermill": {
     "duration": 0.019101,
     "end_time": "2023-04-13T11:10:27.035349",
     "exception": false,
     "start_time": "2023-04-13T11:10:27.016248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "PAD_IDX = fr_vocab['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "036510f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:27.058686Z",
     "iopub.status.busy": "2023-04-13T11:10:27.057795Z",
     "iopub.status.idle": "2023-04-13T11:10:27.065372Z",
     "shell.execute_reply": "2023-04-13T11:10:27.064503Z"
    },
    "papermill": {
     "duration": 0.021446,
     "end_time": "2023-04-13T11:10:27.067528",
     "exception": false,
     "start_time": "2023-04-13T11:10:27.046082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for _, (src, trg) in enumerate(dataloader):\n",
    "        #print (src.size())\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg sent len, batch size]\n",
    "        #output = [trg sent len, batch size, output dim]\n",
    "        \n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg sent len - 1) * batch size]\n",
    "        #output = [(trg sent len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / (len(dataloader)*BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "495056d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:27.091392Z",
     "iopub.status.busy": "2023-04-13T11:10:27.089765Z",
     "iopub.status.idle": "2023-04-13T11:10:27.096834Z",
     "shell.execute_reply": "2023-04-13T11:10:27.095882Z"
    },
    "papermill": {
     "duration": 0.020694,
     "end_time": "2023-04-13T11:10:27.098904",
     "exception": false,
     "start_time": "2023-04-13T11:10:27.078210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for _, (src, trg) in enumerate(dataloader):\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg sent len, batch size]\n",
    "            #output = [trg sent len, batch size, output dim]\n",
    "\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg sent len - 1) * batch size]\n",
    "            #output = [(trg sent len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / (len(dataloader)*BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdafd01d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:27.121940Z",
     "iopub.status.busy": "2023-04-13T11:10:27.121090Z",
     "iopub.status.idle": "2023-04-13T11:10:27.126191Z",
     "shell.execute_reply": "2023-04-13T11:10:27.125186Z"
    },
    "papermill": {
     "duration": 0.018636,
     "end_time": "2023-04-13T11:10:27.128249",
     "exception": false,
     "start_time": "2023-04-13T11:10:27.109613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time: int, \n",
    "               end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61a42565",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:27.151587Z",
     "iopub.status.busy": "2023-04-13T11:10:27.150679Z",
     "iopub.status.idle": "2023-04-13T11:10:27.155361Z",
     "shell.execute_reply": "2023-04-13T11:10:27.154422Z"
    },
    "papermill": {
     "duration": 0.018227,
     "end_time": "2023-04-13T11:10:27.157412",
     "exception": false,
     "start_time": "2023-04-13T11:10:27.139185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = 'rnn-attn-model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49b9d538",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:27.180601Z",
     "iopub.status.busy": "2023-04-13T11:10:27.179687Z",
     "iopub.status.idle": "2023-04-13T11:10:27.197545Z",
     "shell.execute_reply": "2023-04-13T11:10:27.196626Z"
    },
    "papermill": {
     "duration": 0.031455,
     "end_time": "2023-04-13T11:10:27.199623",
     "exception": false,
     "start_time": "2023-04-13T11:10:27.168168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del df_train\n",
    "del df_val\n",
    "del df_test\n",
    "del data\n",
    "del en_tokenizer\n",
    "del fr_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9fd97b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:10:27.222811Z",
     "iopub.status.busy": "2023-04-13T11:10:27.221886Z",
     "iopub.status.idle": "2023-04-13T11:42:14.283111Z",
     "shell.execute_reply": "2023-04-13T11:42:14.282046Z"
    },
    "papermill": {
     "duration": 1907.087879,
     "end_time": "2023-04-13T11:42:14.298142",
     "exception": false,
     "start_time": "2023-04-13T11:10:27.210263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 6m 23s\n",
      "\tTrain Loss: 0.721 | Train PPL:   2.057\n",
      "\t Val. Loss: 0.725 |  Val. PPL:   2.066\n",
      "Epoch: 02 | Time: 6m 18s\n",
      "\tTrain Loss: 0.631 | Train PPL:   1.880\n",
      "\t Val. Loss: 0.693 |  Val. PPL:   2.000\n",
      "Epoch: 03 | Time: 6m 18s\n",
      "\tTrain Loss: 0.581 | Train PPL:   1.788\n",
      "\t Val. Loss: 0.675 |  Val. PPL:   1.965\n",
      "Epoch: 04 | Time: 6m 20s\n",
      "\tTrain Loss: 0.547 | Train PPL:   1.728\n",
      "\t Val. Loss: 0.665 |  Val. PPL:   1.944\n",
      "Epoch: 05 | Time: 6m 26s\n",
      "\tTrain Loss: 0.521 | Train PPL:   1.684\n",
      "\t Val. Loss: 0.660 |  Val. PPL:   1.935\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, val_loader, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "967bdf05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T11:42:14.322852Z",
     "iopub.status.busy": "2023-04-13T11:42:14.321914Z",
     "iopub.status.idle": "2023-04-13T11:42:22.237660Z",
     "shell.execute_reply": "2023-04-13T11:42:22.236550Z"
    },
    "papermill": {
     "duration": 7.930528,
     "end_time": "2023-04-13T11:42:22.240023",
     "exception": false,
     "start_time": "2023-04-13T11:42:14.309495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.655 | Test PPL:   1.925 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "test_loss = evaluate(model, test_loader, criterion)\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2024.7121,
   "end_time": "2023-04-13T11:42:25.859838",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-13T11:08:41.147738",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
